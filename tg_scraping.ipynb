{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pytz import utc\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV-channels "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert json files into csv & check speed for finding last id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'channel_id': 'int32', 'channel_name': 'str', 'msg_id': 'int32', 'message': 'str',\n",
    "       'cleaned_message': 'str', 'date': 'str', 'views': 'int32', 'number_replies': 'int32', 'number_forwards': 'int32',\n",
    "       'contains_media': 'bool', 'media_type': 'str', 'has_url': 'bool', 'url': 'str', 'domain': 'str',\n",
    "       'document_type': 'str'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_id NO\n",
      "channel_name NO\n",
      "msg_id NO\n",
      "message ok\n",
      "cleaned_message NO\n",
      "date ok\n",
      "views ok\n",
      "number_replies NO\n",
      "number_forwards NO\n",
      "contains_media NO\n",
      "media_type NO\n",
      "has_url NO\n",
      "url NO\n",
      "domain NO\n",
      "document_type NO\n"
     ]
    }
   ],
   "source": [
    "for t in dtypes.keys():\n",
    "    if t in df.columns: print(f\"{t} ok\")\n",
    "    else: print(f\"{t} NO\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download messages as per last id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Init program at Sat Jul  1 20:22:54 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rt_russian\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n",
      "\n",
      "End program at Sat Jul  1 20:23:11 2023\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_name = 'rt_russian'\n",
    "last_id = 161821\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "os.system(f\"python3 main.py --telegram-channel {channel_name} --min-id {last_id} -o {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_48073/2639543589.py:1: DtypeWarning: Columns (21,25,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{path}/{channel_name}/{channel_name}_messages.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{path}/{channel_name}/{channel_name}_messages.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07777707887784627"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'].isna().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping rt_russian from 161821...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:05 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rt_russian\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_request_x', 'channel_req_targeted_by_x', 'counter_x', 'source_x', 'from_messages_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:35:21 2023\n",
      "\n",
      "\n",
      "Done scraping rt_russian!\n",
      "Scraping ntvnews from 115584...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:22 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> ntvnews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:35:42 2023\n",
      "\n",
      "\n",
      "Done scraping ntvnews!\n",
      "Scraping tvrussia1 from 18678...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:43 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> tvrussia1\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'source_x', 'channel_req_targeted_by_x', 'channel_request_x', 'counter_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:35:49 2023\n",
      "\n",
      "\n",
      "Done scraping tvrussia1!\n",
      "Scraping bbcrussian from 47948...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:50 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> bbcrussian\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:35:56 2023\n",
      "\n",
      "\n",
      "Done scraping bbcrussian!\n",
      "Scraping news_1tv from 21570...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:57 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> news_1tv\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'source_x', 'from_messages_x', 'counter_x', 'channel_request_x', 'channel_req_targeted_by_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:36:11 2023\n",
      "\n",
      "\n",
      "Done scraping news_1tv!\n",
      "Scraping redakciya_channel from 20311...\n",
      "\n",
      "Init program at Mon Jul  3 17:36:12 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> redakciya_channel\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:36:17 2023\n",
      "\n",
      "\n",
      "Done scraping redakciya_channel!\n",
      "Scraping meduzalive from 85602...\n",
      "\n",
      "Init program at Mon Jul  3 17:36:17 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> meduzalive\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'source_x', 'channel_request_x', 'channel_req_targeted_by_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:36:28 2023\n",
      "\n",
      "\n",
      "Done scraping meduzalive!\n",
      "Scraping mediazzzona from 0...\n",
      "\n",
      "Init program at Mon Jul  3 17:36:28 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> mediazzzona\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:38:53 2023\n",
      "\n",
      "\n",
      "Done scraping mediazzzona!\n",
      "Scraping thebell_io from 23281...\n",
      "\n",
      "Init program at Mon Jul  3 17:38:54 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> thebell_io\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'channel_req_targeted_by_x', 'source_x', 'channel_request_x', 'counter_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:38:58 2023\n",
      "\n",
      "\n",
      "Done scraping thebell_io!\n",
      "Scraping rian_ru from 206025...\n",
      "\n",
      "Init program at Mon Jul  3 17:38:59 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rian_ru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:05 2023\n",
      "\n",
      "\n",
      "Done scraping rian_ru!\n",
      "Scraping readovkanews from 60968...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:05 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> readovkanews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'counter_x', 'from_messages_x', 'channel_request_x', 'channel_req_targeted_by_x', 'source_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:13 2023\n",
      "\n",
      "\n",
      "Done scraping readovkanews!\n",
      "Scraping novaya_pishet from 40765...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:14 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> novaya_pishet\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:18 2023\n",
      "\n",
      "\n",
      "Done scraping novaya_pishet!\n",
      "Scraping rbc_news from 76469...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:18 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rbc_news\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_req_targeted_by_x', 'from_messages_x', 'counter_x', 'source_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:27 2023\n",
      "\n",
      "\n",
      "Done scraping rbc_news!\n",
      "Scraping zvezdanews from 121716...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:27 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> zvezdanews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:34 2023\n",
      "\n",
      "\n",
      "Done scraping zvezdanews!\n",
      "Scraping aifonline from 50223...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:34 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> aifonline\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_request_x', 'counter_x', 'channel_req_targeted_by_x', 'from_messages_x', 'source_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:46 2023\n",
      "\n",
      "\n",
      "Done scraping aifonline!\n",
      "Scraping BFMnews from 32214...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:46 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> BFMnews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:50 2023\n",
      "\n",
      "\n",
      "Done scraping BFMnews!\n",
      "Scraping fontankaspb from 40932...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:51 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> fontankaspb\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'channel_req_targeted_by_x', 'source_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:56 2023\n",
      "\n",
      "\n",
      "Done scraping fontankaspb!\n",
      "Scraping forbesrussia from 53117...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:57 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> forbesrussia\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:02 2023\n",
      "\n",
      "\n",
      "Done scraping forbesrussia!\n",
      "Scraping gazetaru from 16680...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:03 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> gazetaru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_request_x', 'source_x', 'from_messages_x', 'counter_x', 'channel_req_targeted_by_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:09 2023\n",
      "\n",
      "\n",
      "Done scraping gazetaru!\n",
      "Scraping interfaxonline from 33226...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:09 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> interfaxonline\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:14 2023\n",
      "\n",
      "\n",
      "Done scraping interfaxonline!\n",
      "Scraping izvestia from 134449...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:14 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> izvestia\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'source_x', 'channel_req_targeted_by_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:26 2023\n",
      "\n",
      "\n",
      "Done scraping izvestia!\n",
      "Scraping kommersant from 52082...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:27 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> kommersant\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:34 2023\n",
      "\n",
      "\n",
      "Done scraping kommersant!\n",
      "Scraping lentadnya from 82967...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:35 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> lentadnya\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'channel_req_targeted_by_x', 'source_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:43 2023\n",
      "\n",
      "\n",
      "Done scraping lentadnya!\n",
      "Scraping lifenews from 97755...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:44 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> lifenews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:47 2023\n",
      "\n",
      "\n",
      "Done scraping lifenews!\n",
      "Scraping mk_ru from 33845...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:48 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> mk_ru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_request_x', 'counter_x', 'from_messages_x', 'channel_req_targeted_by_x', 'source_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:57 2023\n",
      "\n",
      "\n",
      "Done scraping mk_ru!\n",
      "Scraping novaya_europe from 18929...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:57 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> novaya_europe\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:05 2023\n",
      "\n",
      "\n",
      "Done scraping novaya_europe!\n",
      "Scraping radiosvoboda from 42681...\n",
      "\n",
      "Init program at Mon Jul  3 17:41:05 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> radiosvoboda\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'counter_x', 'channel_request_x', 'source_x', 'channel_req_targeted_by_x', 'from_messages_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:24 2023\n",
      "\n",
      "\n",
      "Done scraping radiosvoboda!\n",
      "Scraping rentv_news from 99623...\n",
      "\n",
      "Init program at Mon Jul  3 17:41:25 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rentv_news\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:34 2023\n",
      "\n",
      "\n",
      "Done scraping rentv_news!\n",
      "Scraping rgrunews from 79290...\n",
      "\n",
      "Init program at Mon Jul  3 17:41:34 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rgrunews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'counter_x', 'channel_req_targeted_by_x', 'from_messages_x', 'source_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:43 2023\n",
      "\n",
      "\n",
      "Done scraping rgrunews!\n",
      "Scraping riafan from 138110...\n",
      "\n",
      "Init program at Mon Jul  3 17:41:44 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> riafan\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:58 2023\n",
      "\n",
      "\n",
      "Done scraping riafan!\n",
      "Scraping rusvesnasu from 26800...\n",
      "\n",
      "Init program at Mon Jul  3 17:42:00 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rusvesnasu\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'source_x', 'channel_req_targeted_by_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:42:08 2023\n",
      "\n",
      "\n",
      "Done scraping rusvesnasu!\n",
      "Scraping svpressaru from 19835...\n",
      "\n",
      "Init program at Mon Jul  3 17:42:09 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> svpressaru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:42:13 2023\n",
      "\n",
      "\n",
      "Done scraping svpressaru!\n",
      "Scraping tass_agency from 196757...\n",
      "\n",
      "Init program at Mon Jul  3 17:42:13 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> tass_agency\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327,336,337) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_req_targeted_by_x', 'channel_request_x', 'counter_x', 'source_x', 'from_messages_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:42:36 2023\n",
      "\n",
      "\n",
      "Done scraping tass_agency!\n",
      "Scraping truekpru from 123477...\n",
      "\n",
      "Init program at Mon Jul  3 17:42:37 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> truekpru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327,336,337) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:43:03 2023\n",
      "\n",
      "\n",
      "Done scraping truekpru!\n",
      "Scraping uranews from 76922...\n",
      "\n",
      "Init program at Mon Jul  3 17:43:04 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> uranews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327,336,337) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'source_x', 'channel_req_targeted_by_x', 'from_messages_x', 'counter_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:43:09 2023\n",
      "\n",
      "\n",
      "Done scraping uranews!\n",
      "Scraping vedomosti from 0...\n",
      "\n",
      "Init program at Mon Jul  3 17:43:10 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> vedomosti\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load csv_channels\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# path to json folders\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "\n",
    "# download new messages for each channel\n",
    "for i, row in df_channels.iterrows():\n",
    "    last_id = int(row['last_id']) if not np.isnan(row['last_id']) else 0\n",
    "    channel_name = row['channel_name']\n",
    "    # run scraper for each channel\n",
    "    print(f\"Scraping {channel_name} from {last_id}...\")\n",
    "    os.system(f\"python3 main.py --telegram-channel {channel_name} --min-id {last_id} -o {path} > download_log.txt\")\n",
    "    print(f\"Done scraping {channel_name}!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-load processing (convert json to csv & store last_id into channels.csv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking last_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_50407/908211125.py:4: DtypeWarning: Columns (11,13,14,15,21,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csv = pd.read_csv(f\"{path}/{channel_name}/{channel_name}_messages.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "# check that last_id in channels.csv, json and csv are the same\n",
    "channel_name = 'lentadnya'\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "df_csv = pd.read_csv(f\"{path}/{channel_name}/{channel_name}_messages.csv\", index_col=0)\n",
    "with open(f'{path}/{channel_name}/{channel_name}_messages.json') as f:\n",
    "    data = json.load(f)\n",
    "    df_json = pd.DataFrame.from_dict(data['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv['id'].max() == df_json['id'].min() == df_channels[df_channels['channel_name'] == channel_name]['last_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82967, 82967, nan)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels = pd.read_csv('channels.csv')\n",
    "df_csv['id'].max(), df_json['id'].max(), df_channels[df_channels['channel_name'] == channel_name]['last_id'].values[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean texts, remvove NaN, json2csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis_and_links(text):\n",
    "    # Unicode range for emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                               \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "                               \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "                               \"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    # Regular expression for URLs\n",
    "    url_pattern = re.compile(r\"http\\S+|www\\S+\")\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = url_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove any remaining variation selectors\n",
    "    text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')\n",
    "\n",
    "    #Remove Foreign Agent text\n",
    "    ino_text1 = '  \\(\\)   \\(\\)     ,    ,  \\(\\)   ,    '\n",
    "    ino_text2 = '  \\(\\)      THE BELL     '\n",
    "    for ino_text in [ino_text1, ino_text2]:\n",
    "        text = text.replace(ino_text, '')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      "  2%|         | 1/48 [00:08<06:59,  8.93s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (17,19,21,25,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      "  6%|         | 3/48 [00:19<04:11,  5.60s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (17,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      "  8%|         | 4/48 [00:31<06:03,  8.25s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (19,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 10%|         | 5/48 [00:34<04:24,  6.15s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (21,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 12%|        | 6/48 [00:36<03:23,  4.85s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (21,27,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 17%|        | 8/48 [01:14<07:33, 11.33s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 19%|        | 9/48 [01:20<06:11,  9.53s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,17,21,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 21%|        | 10/48 [01:27<05:43,  9.04s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,21,25,27,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 25%|       | 12/48 [01:40<04:36,  7.67s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (17,21,25,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 27%|       | 13/48 [01:52<05:15,  9.01s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (17,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 29%|       | 14/48 [01:58<04:35,  8.10s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (17,19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 31%|      | 15/48 [02:08<04:45,  8.65s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 33%|      | 16/48 [02:12<03:44,  7.03s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 35%|      | 17/48 [02:16<03:10,  6.15s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (17,19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 38%|      | 18/48 [02:20<02:50,  5.68s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 40%|      | 19/48 [02:22<02:12,  4.59s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (17,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 42%|     | 20/48 [02:27<02:04,  4.45s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,17,19,21,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 44%|     | 21/48 [02:35<02:33,  5.67s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,17,19,21,25,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 46%|     | 22/48 [02:39<02:16,  5.23s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,21,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 48%|     | 23/48 [02:45<02:18,  5.52s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,17,19,21,25,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 50%|     | 24/48 [02:53<02:25,  6.08s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 52%|    | 25/48 [02:56<01:57,  5.09s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 56%|    | 27/48 [03:13<02:31,  7.22s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 58%|    | 28/48 [03:19<02:15,  6.75s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,19,21,25,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 60%|    | 29/48 [03:25<02:04,  6.55s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,17,19,21,25,29,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 65%|   | 31/48 [03:42<01:59,  7.05s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (19,21,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 67%|   | 32/48 [03:45<01:36,  6.06s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,17,21,25,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 69%|   | 33/48 [03:57<01:57,  7.83s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (21,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 71%|   | 34/48 [04:08<02:03,  8.83s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,21,25,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 75%|  | 36/48 [04:25<01:44,  8.71s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (19,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 81%| | 39/48 [04:29<00:40,  4.53s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 83%| | 40/48 [04:34<00:37,  4.63s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 88%| | 42/48 [04:38<00:21,  3.54s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (19,21,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      " 92%|| 44/48 [04:56<00:21,  5.31s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/2436749393.py:45: DtypeWarning: Columns (11,13,14,15,21,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c, index_col=0)\n",
      "100%|| 48/48 [04:59<00:00,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing folders: ['vestiru24', 'tsargradtv', 'tvc_ru', 'strelkovii', 'concordgroup_official']\n",
      "last_id in channels.csv updated, df_stat.csv saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load csv_channels\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# path to json folders (till data folder)\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "missing_folders = []\n",
    "start_time = time.time()\n",
    "df_stat = pd.DataFrame()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# convert json files to csv & update last_id\n",
    "for i, row in tqdm(df_channels.iterrows(), total=df_channels.shape[0]):\n",
    "    channel_name = row['channel_name']\n",
    "    # add channel_name to df_stat\n",
    "    df_stat.loc[i, 'channel_name'] = channel_name\n",
    "    # check if channel_name exists in the folder or marked as ignore\n",
    "    if os.path.exists(f'{path}/{channel_name}') and not row['ignore']=='y':\n",
    "        # read json file & find the last message id\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.json') as f:\n",
    "            data = json.load(f)\n",
    "            df_new = pd.DataFrame.from_dict(data['messages'])\n",
    "            # constants\n",
    "            df_new['channel_id'] = df_new.peer_id[0]['channel_id']\n",
    "            df_new['channel_name'] = row['channel_name']\n",
    "            # find the last id\n",
    "            last_id = max(df_new['id'])\n",
    "            df_stat.loc[i, 'last_id'] = last_id\n",
    "            df_stat.loc[i, 'N_new_messages'] = df_new.shape[0]\n",
    "        # remove messages with NaN & digests\n",
    "        df_new = df_new[~df_new['message'].isna()]\n",
    "        digest_filter = ' |  | |  |  '\n",
    "        df_new = df_new[~df_new['message'].str.contains(digest_filter)]\n",
    "        # clean text\n",
    "        df_new['cleaned_message'] = df_new['message'].apply(lambda x: remove_emojis_and_links(x))\n",
    "        \n",
    "        # update csv-database with new messages\n",
    "        csv_path = f'{path}/{channel_name}/{channel_name}_messages.csv'\n",
    "        \n",
    "        # check if csv exists\n",
    "        if not os.path.exists(csv_path):\n",
    "            df_new.to_csv(csv_path)\n",
    "        else:\n",
    "            with open(csv_path) as c:\n",
    "                df = pd.read_csv(c, index_col=0)\n",
    "                # add new rows from df_new\n",
    "                df = df.append(df_new, ignore_index=True)\n",
    "                df.to_csv(f'{path}/{channel_name}/{channel_name}_messages.csv')\n",
    "        \n",
    "        # update last_id (for channels.csv)\n",
    "        df_channels.loc[i, 'last_id'] = last_id\n",
    "        finish_time = time.time()\n",
    "        df_stat.loc[i, 'time'] = round(finish_time - start_time, 2)\n",
    "        start_time = finish_time\n",
    "    else:\n",
    "        missing_folders.append(channel_name)\n",
    "\n",
    "print(f\"Missing folders: {missing_folders}\")\n",
    "df_channels.to_csv('channels.csv', index=False)\n",
    "df_stat.to_csv('stat.csv', index=False)\n",
    "print(\"last_id in channels.csv updated, df_stat.csv saved\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_46539/375518014.py:1: DtypeWarning: Columns (17,19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Volumes/netac/Politics_economy/_news narratives/TG scraping/telegram-tracker/output/data/aifonline/aifonline_messages.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Volumes/netac/Politics_economy/_news narratives/TG scraping/telegram-tracker/output/data/aifonline/aifonline_messages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_</th>\n",
       "      <th>id</th>\n",
       "      <th>peer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>out</th>\n",
       "      <th>mentioned</th>\n",
       "      <th>media_unread</th>\n",
       "      <th>silent</th>\n",
       "      <th>...</th>\n",
       "      <th>replies</th>\n",
       "      <th>edit_date</th>\n",
       "      <th>post_author</th>\n",
       "      <th>grouped_id</th>\n",
       "      <th>reactions</th>\n",
       "      <th>restriction_reason</th>\n",
       "      <th>ttl_period</th>\n",
       "      <th>action</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Message</td>\n",
       "      <td>50223</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1137457075}</td>\n",
       "      <td>2023-06-16 20:26:50+00:00</td>\n",
       "      <td>     ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1137457075</td>\n",
       "      <td>aifonline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Message</td>\n",
       "      <td>50222</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1137457075}</td>\n",
       "      <td>2023-06-16 20:14:13+00:00</td>\n",
       "      <td>   ,      2023 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1137457075</td>\n",
       "      <td>aifonline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Message</td>\n",
       "      <td>50221</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1137457075}</td>\n",
       "      <td>2023-06-16 20:10:09+00:00</td>\n",
       "      <td>     ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1137457075</td>\n",
       "      <td>aifonline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Message</td>\n",
       "      <td>50220</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1137457075}</td>\n",
       "      <td>2023-06-16 20:08:26+00:00</td>\n",
       "      <td>       . ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1137457075</td>\n",
       "      <td>aifonline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Message</td>\n",
       "      <td>50219</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1137457075}</td>\n",
       "      <td>2023-06-16 19:30:52+00:00</td>\n",
       "      <td>    , ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1137457075</td>\n",
       "      <td>aifonline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        _     id                                         peer_id  \\\n",
       "0           0  Message  50223  {'_': 'PeerChannel', 'channel_id': 1137457075}   \n",
       "1           1  Message  50222  {'_': 'PeerChannel', 'channel_id': 1137457075}   \n",
       "2           2  Message  50221  {'_': 'PeerChannel', 'channel_id': 1137457075}   \n",
       "3           3  Message  50220  {'_': 'PeerChannel', 'channel_id': 1137457075}   \n",
       "4           4  Message  50219  {'_': 'PeerChannel', 'channel_id': 1137457075}   \n",
       "\n",
       "                        date  \\\n",
       "0  2023-06-16 20:26:50+00:00   \n",
       "1  2023-06-16 20:14:13+00:00   \n",
       "2  2023-06-16 20:10:09+00:00   \n",
       "3  2023-06-16 20:08:26+00:00   \n",
       "4  2023-06-16 19:30:52+00:00   \n",
       "\n",
       "                                             message    out  mentioned  \\\n",
       "0       ...  False      False   \n",
       "1     ,      2023 ...  False      False   \n",
       "2       ...  False      False   \n",
       "3         . ...  False      False   \n",
       "4      , ...  False      False   \n",
       "\n",
       "   media_unread  silent  ...  replies edit_date  post_author grouped_id  \\\n",
       "0         False   False  ...      NaN       NaN          NaN        NaN   \n",
       "1         False   False  ...      NaN       NaN          NaN        NaN   \n",
       "2         False   False  ...      NaN       NaN          NaN        NaN   \n",
       "3         False   False  ...      NaN       NaN          NaN        NaN   \n",
       "4         False   False  ...      NaN       NaN          NaN        NaN   \n",
       "\n",
       "  reactions restriction_reason  ttl_period action  channel_id channel_name  \n",
       "0       NaN                 []         NaN    NaN  1137457075    aifonline  \n",
       "1       NaN                 []         NaN    NaN  1137457075    aifonline  \n",
       "2       NaN                 []         NaN    NaN  1137457075    aifonline  \n",
       "3       NaN                 []         NaN    NaN  1137457075    aifonline  \n",
       "4       NaN                 []         NaN    NaN  1137457075    aifonline  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# calculate embeddings for all csv files\n",
    "# sentence_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\") # a bit faster, less precise\n",
    "sentence_model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\") # a bit slower, more precise\n",
    "\n",
    "for i, row in df_channels.iterrows():\n",
    "    channel_name = row['channel_name']\n",
    "    # set last_id to 0\n",
    "    row['last_id'] = 0\n",
    "    # check if channel_name exists in the folder or marked as ignore\n",
    "    if os.path.exists(f'{path}/{channel_name}') and not row['ignore']=='y':\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.csv') as f:\n",
    "            df = pd.read_csv(f)\n",
    "            if 'Unnamed: 0' in df.columns: df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "            # clean text\n",
    "            df['cleaned_message'] = df['message'].apply(lambda x: remove_emojis_and_links(x))\n",
    "            # remove Foreign Agent text\n",
    "            ino_text1 = '  \\(\\)   \\(\\)     ,    ,  \\(\\)   ,    '\n",
    "            ino_text2 = '  \\(\\)      THE BELL     '\n",
    "            df['cleaned_message'] = df['cleaned_message'].apply(lambda x: re.sub(ino_text1, '', x))\n",
    "            df['cleaned_message'] = df['cleaned_message'].apply(lambda x: re.sub(ino_text2, '', x))\n",
    "\n",
    "            \n",
    "            # calculate embeddings & save to numpy\n",
    "            embeddings = sentence_model.encode(df['cleaned_message'].tolist(), show_progress_bar=True)\n",
    "            np.save(f'{path}/{channel_name}/{channel_name}_embeddings.npy', embeddings)\n",
    "            print(f'{i} {channel_name} embeddings saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260622817"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constants\n",
    "channel_id = df.peer_id[0]['channel_id']\n",
    "channel_name = row['channel_name']\n",
    "\n",
    "# vars\n",
    "msg_id = df.id\n",
    "# number_replies = df['replies'].apply(lambda x: x['replies']) - need correction\n",
    "number_forwards = df.forwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_', 'id', 'peer_id', 'date', 'message', 'out', 'mentioned',\n",
       "       'media_unread', 'silent', 'post', 'from_scheduled', 'legacy',\n",
       "       'edit_hide', 'pinned', 'noforwards', 'from_id', 'fwd_from',\n",
       "       'via_bot_id', 'reply_to', 'media', 'reply_markup', 'entities', 'views',\n",
       "       'forwards', 'replies', 'edit_date', 'post_author', 'grouped_id',\n",
       "       'reactions', 'restriction_reason', 'ttl_period', 'action'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_': 'MessageMediaDocument',\n",
       " 'nopremium': False,\n",
       " 'document': {'_': 'Document',\n",
       "  'id': 5215252386645291684,\n",
       "  'access_hash': 3073411139599307038,\n",
       "  'file_reference': \"b'\\\\x02K#\\\\x93\\\\xe1\\\\x00\\\\x00\\\\xee(d\\\\x8c\\\\xbdK\\\\x0bT\\\\xe0\\\\xe4\\\\x843w\\\\xec\\\\xa6\\\\xc3\\\\x9a\\\\x89\\\\xc5}\\\\x81\\\\xb7'\",\n",
       "  'date': '2023-06-16 19:46:52+00:00',\n",
       "  'mime_type': 'video/mp4',\n",
       "  'size': 278624,\n",
       "  'dc_id': 2,\n",
       "  'attributes': [{'_': 'DocumentAttributeVideo',\n",
       "    'duration': 6,\n",
       "    'w': 360,\n",
       "    'h': 640,\n",
       "    'round_message': False,\n",
       "    'supports_streaming': True},\n",
       "   {'_': 'DocumentAttributeFilename',\n",
       "    'file_name': 'video_2023-06-16_22-42-24.mp4'}],\n",
       "  'thumbs': [{'_': 'PhotoStrippedSize',\n",
       "    'type': 'i',\n",
       "    'bytes': \"b'\\\\x01(\\\\x16\\\\xc5\\\\xa2\\\\x8a(\\\\x00\\\\xa2\\\\x8a(\\\\x01A\\\\xc7aF}\\\\x85%\\\\x14\\\\x00\\\\xb4QE\\\\x00%\\\\x14Q@\\\\x0bE\\\\x14P\\\\x07'\"},\n",
       "   {'_': 'PhotoSize', 'type': 'm', 'w': 180, 'h': 320, 'size': 1458}],\n",
       "  'video_thumbs': []},\n",
       " 'ttl_seconds': None}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()['media'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE-TIME PROCEDURES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clean messages -> col 'cleaned_message'\n",
    "2. Remove NaN and digests\n",
    "3. Update last_id in channels.csv\n",
    "4. Link embeddings with csv databases\n",
    "5. Remove doublicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rt_russian last: 164235\n",
      "Time elapsed: 4.94 seconds\n",
      "1 ntvnews last: 116705\n",
      "Time elapsed: 0.09 seconds\n",
      "2 tvrussia1 last: 19538\n",
      "Time elapsed: 0.11 seconds\n",
      "3 bbcrussian last: 48798\n",
      "Time elapsed: 0.08 seconds\n",
      "4 news_1tv last: 22056\n",
      "Time elapsed: 0.03 seconds\n",
      "5 redakciya_channel last: 21152\n",
      "Time elapsed: 0.04 seconds\n",
      "6 meduzalive last: 87152\n",
      "Time elapsed: 0.2 seconds\n",
      "7 mediazzzona last: 12101\n",
      "Time elapsed: 2.25 seconds\n",
      "8 thebell_io last: 23585\n",
      "Time elapsed: 0.1 seconds\n",
      "9 rian_ru last: 207734\n",
      "Time elapsed: 0.04 seconds\n",
      "10 readovkanews last: 61903\n",
      "Time elapsed: 0.07 seconds\n",
      "11 novaya_pishet last: 41023\n",
      "Time elapsed: 0.02 seconds\n",
      "12 rbc_news last: 77596\n",
      "Time elapsed: 0.07 seconds\n",
      "13 zvezdanews last: 123306\n",
      "Time elapsed: 0.06 seconds\n",
      "14 aifonline last: 52411\n",
      "Time elapsed: 0.19 seconds\n",
      "15 BFMnews last: 32808\n",
      "Time elapsed: 0.03 seconds\n",
      "16 fontankaspb last: 41786\n",
      "Time elapsed: 0.04 seconds\n",
      "17 forbesrussia last: 53822\n",
      "Time elapsed: 0.03 seconds\n",
      "18 gazetaru last: 17701\n",
      "Time elapsed: 0.08 seconds\n",
      "19 interfaxonline last: 33741\n",
      "Time elapsed: 0.02 seconds\n",
      "20 izvestia last: 135989\n",
      "Time elapsed: 0.05 seconds\n",
      "21 kommersant last: 52863\n",
      "Time elapsed: 0.05 seconds\n",
      "22 lentadnya last: 84585\n",
      "Time elapsed: 0.11 seconds\n",
      "23 lifenews last: 98004\n",
      "Time elapsed: 0.02 seconds\n",
      "24 mk_ru last: 35368\n",
      "Time elapsed: 0.05 seconds\n",
      "25 novaya_europe last: 19900\n",
      "Time elapsed: 0.13 seconds\n",
      "26 radiosvoboda last: 43601\n",
      "Time elapsed: 0.07 seconds\n",
      "27 rentv_news last: 101468\n",
      "Time elapsed: 0.1 seconds\n",
      "28 rgrunews last: 80629\n",
      "Time elapsed: 0.06 seconds\n",
      "29 riafan last: 139454\n",
      "Time elapsed: 0.06 seconds\n",
      "30 rusvesnasu last: 27048\n",
      "Time elapsed: 0.02 seconds\n",
      "31 svpressaru last: 20000\n",
      "Time elapsed: 0.05 seconds\n",
      "32 tass_agency last: 199324\n",
      "Time elapsed: 0.09 seconds\n",
      "33 truekpru last: 124717\n",
      "Time elapsed: 0.12 seconds\n",
      "34 uranews last: 77603\n",
      "Time elapsed: 0.04 seconds\n",
      "35 vedomosti last: 34033\n",
      "Time elapsed: 3.44 seconds\n",
      "36 vestiru24 last: 78732\n",
      "Time elapsed: 3.63 seconds\n",
      "37 tsargradtv last: 49015\n",
      "Time elapsed: 6.26 seconds\n",
      "38 sashakots last: 40743\n",
      "Time elapsed: 0.28 seconds\n",
      "39 rybar last: 49285\n",
      "Time elapsed: 0.04 seconds\n",
      "40 voenacher last: 47737\n",
      "Time elapsed: 0.06 seconds\n",
      "41 vysokygovorit last: 12163\n",
      "Time elapsed: 0.01 seconds\n",
      "42 SolovievLive last: 192455\n",
      "Time elapsed: 0.18 seconds\n",
      "43 margaritasimonyan last: 13079\n",
      "Time elapsed: 0.02 seconds\n",
      "44 breakingmash last: 45597\n",
      "Time elapsed: 0.02 seconds\n",
      "45 tvc_ru last: 55158\n",
      "Time elapsed: 2.69 seconds\n",
      "46 strelkovii last: 5858\n",
      "Time elapsed: 0.45 seconds\n",
      "47 concordgroup_official last: 1304\n",
      "Time elapsed: 0.08 seconds\n",
      "Missing folders: []\n",
      "last_id updated\n"
     ]
    }
   ],
   "source": [
    "# ONLY UPDATE LAST_ID in csv_channels\n",
    "\n",
    "# load csv_channels\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# path to json folders\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "\n",
    "missing_folders = []\n",
    "\n",
    "start_time = time.time()\n",
    "# iterate over rows, set last_id and show missing folders\n",
    "for i, row in df_channels.iterrows():\n",
    "    channel_name = row['channel_name']\n",
    "    # set last_id to 0\n",
    "    row['last_id'] = 0\n",
    "    # check channel_name exists in the folder\n",
    "    if os.path.exists(f'{path}/{channel_name}'):\n",
    "        # read json file & find the last message id\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.json') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame.from_dict(data['messages'])\n",
    "            last_id = max(df['id'])\n",
    "            # update channels csv\n",
    "            df_channels.loc[i, 'last_id'] = last_id\n",
    "        print(f'{i} {channel_name} last: {last_id}')\n",
    "    else:\n",
    "        missing_folders.append(channel_name)\n",
    "    finish_time = time.time()\n",
    "    print(f\"Time elapsed: {round(finish_time - start_time, 2)} seconds\")\n",
    "    start_time = finish_time\n",
    "print(f\"Missing folders: {missing_folders}\")\n",
    "df_channels.to_csv('channels.csv', index=False)\n",
    "print(\"last_id updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/1473799604.py:15: DtypeWarning: Columns (21,25,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "  2%|         | 1/48 [00:30<23:46, 30.35s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/1473799604.py:15: DtypeWarning: Columns (17,19,21,25,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "  6%|         | 3/48 [00:45<08:57, 11.95s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/1473799604.py:15: DtypeWarning: Columns (17,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "  8%|         | 4/48 [01:02<10:14, 13.97s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/1473799604.py:15: DtypeWarning: Columns (19,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 12%|        | 6/48 [01:10<05:44,  8.20s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_58116/1473799604.py:15: DtypeWarning: Columns (21,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 15%|        | 7/48 [01:49<10:41, 15.65s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data/mediazzzona/mediazzzona_messages.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# check if channel_name exists in the folder or marked as ignore\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mchannel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m row[\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mpath\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mchannel_name\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mchannel_name\u001b[39m}\u001b[39;49;00m\u001b[39m_messages.csv\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     15\u001b[0m         df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(f)\n\u001b[1;32m     16\u001b[0m         \u001b[39m# remove messages with NaN & digests\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data/mediazzzona/mediazzzona_messages.csv'"
     ]
    }
   ],
   "source": [
    "# CLEAN TEXT IN ALL CSV FILES\n",
    "# load csv_channels\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# path to json folders\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "\n",
    "# clean messages\n",
    "for i, row in tqdm(df_channels.iterrows(), total=df_channels.shape[0]):\n",
    "    channel_name = row['channel_name']\n",
    "    # set last_id to 0\n",
    "    row['last_id'] = 0\n",
    "    # check if channel_name exists in the folder or marked as ignore\n",
    "    if os.path.exists(f'{path}/{channel_name}') and not row['ignore']=='y':\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.csv') as f:\n",
    "            df = pd.read_csv(f)\n",
    "            # remove messages with NaN & digests\n",
    "            df = df[~df['message'].isna()]\n",
    "            digest_filter = ' |  | |  |  '\n",
    "            df = df[~df['message'].str.contains(digest_filter)]\n",
    "            if 'Unnamed: 0' in df.columns: df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "            # clean text\n",
    "            df['cleaned_message'] = df['message'].apply(lambda x: remove_emojis_and_links(x))\n",
    "        # update csv-database with cleaned messages\n",
    "        df.to_csv(f'{path}/{channel_name}/{channel_name}_messages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Database - OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_57367/4121249504.py:1: DtypeWarning: Columns (14,16,17,18,19,22,26,27,28,29,30,33,35,37,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_messages = pd.read_csv('/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/output/data/msgs_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "df_messages = pd.read_csv('/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/output/data/msgs_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 992K messages\n",
      "N of channels 11\n"
     ]
    }
   ],
   "source": [
    "print(f\"The file contains {round(df_messages.shape[0]/1000)}K messages\")\n",
    "print(f\"N of channels {df_messages['channel_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rt_russian           316770\n",
       "rian_ru              204610\n",
       "meduzalive           169360\n",
       "ntvnews              113920\n",
       "readovkanews          59745\n",
       "bbcrussian            46656\n",
       "thebell_io            22537\n",
       "news_1tv              21236\n",
       "redakciya_channel     19167\n",
       "tvrussia1             18105\n",
       "tchantest               168\n",
       "Name: channel_name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages['channel_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rt_russian    158051\n",
       "meduzalive     84680\n",
       "tchantest         84\n",
       "Name: channel_name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages['channel_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['signature', 'channel_id', 'channel_name', 'msg_id', 'message',\n",
       "       'cleaned_message', 'date', 'msg_link', 'msg_from_peer', 'msg_from_id',\n",
       "       'views', 'number_replies', 'number_forwards', 'is_forward',\n",
       "       'forward_msg_from_peer_type', 'forward_msg_from_peer_id',\n",
       "       'forward_msg_from_peer_name', 'forward_msg_date',\n",
       "       'forward_msg_date_string', 'forward_msg_link', 'is_reply',\n",
       "       'reply_to_msg_id', 'reply_msg_link', 'contains_media', 'media_type',\n",
       "       'has_url', 'url', 'domain', 'url_title', 'url_description',\n",
       "       'document_type', 'document_id', 'document_video_duration',\n",
       "       'document_filename', 'poll_id', 'poll_question', 'poll_total_voters',\n",
       "       'poll_results', 'contact_phone_number', 'contact_name',\n",
       "       'contact_userid', 'geo_type', 'lat', 'lng', 'venue_id', 'venue_type',\n",
       "       'venue_title', 'venue_address', 'venue_provider'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messages['date'] = pd.to_datetime(df_messages['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>msg_id</th>\n",
       "      <th>message</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158135</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85602</td>\n",
       "      <td>      ...</td>\n",
       "      <td>2023-06-10 15:01:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158136</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85601</td>\n",
       "      <td>    ...</td>\n",
       "      <td>2023-06-10 14:49:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158137</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85600</td>\n",
       "      <td>       ...</td>\n",
       "      <td>2023-06-10 14:28:35+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158138</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85599</td>\n",
       "      <td>     ...</td>\n",
       "      <td>2023-06-10 14:02:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158139</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85598</td>\n",
       "      <td>   .    ...</td>\n",
       "      <td>2023-06-10 13:50:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206864</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36414</td>\n",
       "      <td>   ?  ,    1 ...</td>\n",
       "      <td>2021-01-01 10:00:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206865</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36413</td>\n",
       "      <td>,     :  ...</td>\n",
       "      <td>2021-01-01 09:49:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206866</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36412</td>\n",
       "      <td>  ,      ...</td>\n",
       "      <td>2021-01-01 08:49:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206867</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36411</td>\n",
       "      <td>\\n      ,  ...</td>\n",
       "      <td>2021-01-01 07:49:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206868</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36410</td>\n",
       "      <td>      ...</td>\n",
       "      <td>2021-01-01 06:49:50+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48734 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel_name  msg_id  \\\n",
       "158135   meduzalive   85602   \n",
       "158136   meduzalive   85601   \n",
       "158137   meduzalive   85600   \n",
       "158138   meduzalive   85599   \n",
       "158139   meduzalive   85598   \n",
       "...             ...     ...   \n",
       "206864   meduzalive   36414   \n",
       "206865   meduzalive   36413   \n",
       "206866   meduzalive   36412   \n",
       "206867   meduzalive   36411   \n",
       "206868   meduzalive   36410   \n",
       "\n",
       "                                                  message  \\\n",
       "158135        ...   \n",
       "158136      ...   \n",
       "158137         ...   \n",
       "158138       ...   \n",
       "158139     .    ...   \n",
       "...                                                   ...   \n",
       "206864     ?  ,    1 ...   \n",
       "206865  ,     :  ...   \n",
       "206866    ,      ...   \n",
       "206867  \\n      ,  ...   \n",
       "206868        ...   \n",
       "\n",
       "                            date  \n",
       "158135 2023-06-10 15:01:23+00:00  \n",
       "158136 2023-06-10 14:49:01+00:00  \n",
       "158137 2023-06-10 14:28:35+00:00  \n",
       "158138 2023-06-10 14:02:10+00:00  \n",
       "158139 2023-06-10 13:50:01+00:00  \n",
       "...                          ...  \n",
       "206864 2021-01-01 10:00:16+00:00  \n",
       "206865 2021-01-01 09:49:50+00:00  \n",
       "206866 2021-01-01 08:49:50+00:00  \n",
       "206867 2021-01-01 07:49:50+00:00  \n",
       "206868 2021-01-01 06:49:50+00:00  \n",
       "\n",
       "[48734 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages[(df_messages['channel_name'] == 'meduzalive') & (df_messages['date'] > utc.localize(datetime(year=2021, month=1, day=1)))][['channel_name', 'msg_id', 'message', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime64[ns, UTC]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages['date'].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## via json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rt_russian last: 161821\n",
      "Time elapsed: 18.83 seconds\n",
      "1 ntvnews last: 115584\n",
      "Time elapsed: 13.87 seconds\n",
      "2 tvrussia1 last: 18678\n",
      "Time elapsed: 0.96 seconds\n",
      "3 bbcrussian last: 47948\n",
      "Time elapsed: 6.33 seconds\n",
      "4 news_1tv last: 21570\n",
      "Time elapsed: 1.0 seconds\n",
      "5 redakciya_channel last: 20311\n",
      "Time elapsed: 2.03 seconds\n",
      "6 meduzalive last: 85602\n",
      "Time elapsed: 35.3 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "8 thebell_io last: 23281\n",
      "Time elapsed: 3.46 seconds\n",
      "9 rian_ru last: 206025\n",
      "Time elapsed: 7.18 seconds\n",
      "10 readovkanews last: 60968\n",
      "Time elapsed: 5.4 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Missing folders: ['mediazzzona', 'novaya_pishet', 'rbc_news', 'zvezdanews', 'aifonline', 'BFMnews', 'fontankaspb', 'forbesrussia', 'gazetaru', 'interfaxonline', 'izvestia', 'kommersant', 'lentadnya', 'lifenews', 'mk_ru', 'novaya_europe', 'radiosvoboda', 'rentv_news', 'rgrunews', 'riafan', 'rusvesnasu', 'svpressaru', 'tass_agency', 'truekpru', 'uranews', 'vedomosti', 'vestiru24', 'tsargradtv', 'sashakots', 'rybar', 'voenacher', 'vysokygovorit', 'SolovievLive', 'margaritasimonyan', 'breakingmash', 'tvc_ru']\n",
      "last_id updated\n"
     ]
    }
   ],
   "source": [
    "# ONLY UPDATE LAST_ID in csv_channels\n",
    "\n",
    "# load csv_channels\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# path to json folders\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "\n",
    "missing_folders = []\n",
    "\n",
    "start_time = time.time()\n",
    "# iterate over rows, set last_id and show missing folders\n",
    "for i, row in df_channels.iterrows():\n",
    "    channel_name = row['channel_name']\n",
    "    # set last_id to 0\n",
    "    row['last_id'] = 0\n",
    "    # check channel_name exists in the folder\n",
    "    if os.path.exists(f'{path}/{channel_name}'):\n",
    "        # read json file & find the last message id\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.json') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame.from_dict(data['messages'])\n",
    "            last_id = max(df['id'])\n",
    "            # update channels csv\n",
    "            df_channels.loc[i, 'last_id'] = last_id\n",
    "        print(f'{i} {channel_name} last: {last_id}')\n",
    "    else:\n",
    "        missing_folders.append(channel_name)\n",
    "    finish_time = time.time()\n",
    "    print(f\"Time elapsed: {round(finish_time - start_time, 2)} seconds\")\n",
    "    start_time = finish_time\n",
    "print(f\"Missing folders: {missing_folders}\")\n",
    "df_channels.to_csv('channels.csv', index=False)\n",
    "print(\"last_id updated\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file\n",
    "with open('/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/output/data/bbcrussian/bbcrussian_messages.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_', 'pts', 'count', 'messages', 'topics', 'chats', 'users', 'inexact', 'offset_id_offset'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert json to dataframe\n",
    "df = pd.DataFrame.from_dict(data['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_', 'id', 'peer_id', 'date', 'message', 'out', 'mentioned',\n",
       "       'media_unread', 'silent', 'post', 'from_scheduled', 'legacy',\n",
       "       'edit_hide', 'pinned', 'noforwards', 'from_id', 'fwd_from',\n",
       "       'via_bot_id', 'reply_to', 'media', 'reply_markup', 'entities', 'views',\n",
       "       'forwards', 'replies', 'edit_date', 'post_author', 'grouped_id',\n",
       "       'reactions', 'restriction_reason', 'ttl_period', 'action'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 0.0024161303427484015)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# share of NaN messages\n",
    "df['message'].isna().sum(), df['message'].isna().sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47948"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the last message id\n",
    "max(df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>id</th>\n",
       "      <th>peer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>out</th>\n",
       "      <th>mentioned</th>\n",
       "      <th>media_unread</th>\n",
       "      <th>silent</th>\n",
       "      <th>post</th>\n",
       "      <th>...</th>\n",
       "      <th>views</th>\n",
       "      <th>forwards</th>\n",
       "      <th>replies</th>\n",
       "      <th>edit_date</th>\n",
       "      <th>post_author</th>\n",
       "      <th>grouped_id</th>\n",
       "      <th>reactions</th>\n",
       "      <th>restriction_reason</th>\n",
       "      <th>ttl_period</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Message</td>\n",
       "      <td>47947</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 16:43:34+00:00</td>\n",
       "      <td>       ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>20108.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Message</td>\n",
       "      <td>47946</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 16:27:18+00:00</td>\n",
       "      <td> : 23 ,   ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>25015.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Message</td>\n",
       "      <td>47942</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 14:30:12+00:00</td>\n",
       "      <td> 478  .  ,  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>44689.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-16 15:46:15+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Message</td>\n",
       "      <td>47935</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 11:40:57+00:00</td>\n",
       "      <td>\"   \".   ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>54462.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-16 12:10:27+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Message</td>\n",
       "      <td>47923</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 07:54:27+00:00</td>\n",
       "      <td>     28   ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>76994.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46426</th>\n",
       "      <td>Message</td>\n",
       "      <td>356</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2016-09-15 10:06:16+00:00</td>\n",
       "      <td> !      :...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46522</th>\n",
       "      <td>Message</td>\n",
       "      <td>256</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2016-05-30 10:49:45+00:00</td>\n",
       "      <td>,    :\\n ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-30 10:50:04+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46531</th>\n",
       "      <td>Message</td>\n",
       "      <td>247</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2016-05-19 11:28:54+00:00</td>\n",
       "      <td>     ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-19 11:29:08+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46631</th>\n",
       "      <td>Message</td>\n",
       "      <td>146</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2016-02-17 08:58:44+00:00</td>\n",
       "      <td>,    . \\n\\n ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46742</th>\n",
       "      <td>Message</td>\n",
       "      <td>30</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2015-12-09 18:44:28+00:00</td>\n",
       "      <td> \"   \".  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-13 16:32:01+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8344 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             _     id                                         peer_id  \\\n",
       "1      Message  47947  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "2      Message  47946  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "6      Message  47942  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "13     Message  47935  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "25     Message  47923  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "...        ...    ...                                             ...   \n",
       "46426  Message    356  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "46522  Message    256  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "46531  Message    247  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "46631  Message    146  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "46742  Message     30  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "\n",
       "                            date  \\\n",
       "1      2023-06-16 16:43:34+00:00   \n",
       "2      2023-06-16 16:27:18+00:00   \n",
       "6      2023-06-16 14:30:12+00:00   \n",
       "13     2023-06-16 11:40:57+00:00   \n",
       "25     2023-06-16 07:54:27+00:00   \n",
       "...                          ...   \n",
       "46426  2016-09-15 10:06:16+00:00   \n",
       "46522  2016-05-30 10:49:45+00:00   \n",
       "46531  2016-05-19 11:28:54+00:00   \n",
       "46631  2016-02-17 08:58:44+00:00   \n",
       "46742  2015-12-09 18:44:28+00:00   \n",
       "\n",
       "                                                 message    out  mentioned  \\\n",
       "1             ...  False      False   \n",
       "2       : 23 ,   ...  False      False   \n",
       "6       478  .  ,  ...  False      False   \n",
       "13     \"   \".   ...  False      False   \n",
       "25          28   ...  False      False   \n",
       "...                                                  ...    ...        ...   \n",
       "46426   !      :...  False      False   \n",
       "46522  ,    :\\n ...  False      False   \n",
       "46531       ...  False      False   \n",
       "46631  ,    . \\n\\n ...  False      False   \n",
       "46742   \"   \".  ...  False      False   \n",
       "\n",
       "       media_unread  silent  post  ...    views  forwards replies  \\\n",
       "1             False   False  True  ...  20108.0      10.0     NaN   \n",
       "2             False   False  True  ...  25015.0      22.0     NaN   \n",
       "6             False   False  True  ...  44689.0      11.0     NaN   \n",
       "13            False   False  True  ...  54462.0     106.0     NaN   \n",
       "25            False   False  True  ...  76994.0     223.0     NaN   \n",
       "...             ...     ...   ...  ...      ...       ...     ...   \n",
       "46426         False   False  True  ...   2757.0       0.0     NaN   \n",
       "46522         False   False  True  ...   2050.0       0.0     NaN   \n",
       "46531         False   False  True  ...   2683.0       0.0     NaN   \n",
       "46631         False   False  True  ...   1730.0       0.0     NaN   \n",
       "46742         False   False  True  ...   1270.0       1.0     NaN   \n",
       "\n",
       "                       edit_date post_author grouped_id reactions  \\\n",
       "1                           None         NaN        NaN       NaN   \n",
       "2                           None         NaN        NaN       NaN   \n",
       "6      2023-06-16 15:46:15+00:00         NaN        NaN       NaN   \n",
       "13     2023-06-16 12:10:27+00:00         NaN        NaN       NaN   \n",
       "25                          None         NaN        NaN       NaN   \n",
       "...                          ...         ...        ...       ...   \n",
       "46426                       None         NaN        NaN       NaN   \n",
       "46522  2016-05-30 10:50:04+00:00         NaN        NaN       NaN   \n",
       "46531  2016-05-19 11:29:08+00:00         NaN        NaN       NaN   \n",
       "46631                       None         NaN        NaN       NaN   \n",
       "46742  2022-06-13 16:32:01+00:00         NaN        NaN       NaN   \n",
       "\n",
       "       restriction_reason ttl_period action  \n",
       "1                      []       None    NaN  \n",
       "2                      []       None    NaN  \n",
       "6                      []       None    NaN  \n",
       "13                     []       None    NaN  \n",
       "25                     []       None    NaN  \n",
       "...                   ...        ...    ...  \n",
       "46426                  []       None    NaN  \n",
       "46522                  []       None    NaN  \n",
       "46531                  []       None    NaN  \n",
       "46631                  []       None    NaN  \n",
       "46742                  []       None    NaN  \n",
       "\n",
       "[8344 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keywords1 = '||||||'\n",
    "keywords2 = '|'\n",
    "\n",
    "df[(df['message'].str.contains(keywords1)) & (df['message'].str.contains(keywords2))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
