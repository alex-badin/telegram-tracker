{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/miniforge3/envs/bertopic/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pytz import utc\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV-channels "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert json files into csv & check speed for finding last id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'channel_id': 'int32', 'channel_name': 'str', 'msg_id': 'int32', 'message': 'str',\n",
    "       'cleaned_message': 'str', 'date': 'str', 'views': 'int32', 'number_replies': 'int32', 'number_forwards': 'int32',\n",
    "       'contains_media': 'bool', 'media_type': 'str', 'has_url': 'bool', 'url': 'str', 'domain': 'str',\n",
    "       'document_type': 'str'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_id NO\n",
      "channel_name NO\n",
      "msg_id NO\n",
      "message ok\n",
      "cleaned_message NO\n",
      "date ok\n",
      "views ok\n",
      "number_replies NO\n",
      "number_forwards NO\n",
      "contains_media NO\n",
      "media_type NO\n",
      "has_url NO\n",
      "url NO\n",
      "domain NO\n",
      "document_type NO\n"
     ]
    }
   ],
   "source": [
    "for t in dtypes.keys():\n",
    "    if t in df.columns: print(f\"{t} ok\")\n",
    "    else: print(f\"{t} NO\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download messages as per last id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Init program at Sat Jul  1 20:22:54 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rt_russian\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n",
      "\n",
      "End program at Sat Jul  1 20:23:11 2023\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_name = 'rt_russian'\n",
    "last_id = 161821\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "os.system(f\"python3 main.py --telegram-channel {channel_name} --min-id {last_id} -o {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_48073/2639543589.py:1: DtypeWarning: Columns (21,25,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f\"{path}/{channel_name}/{channel_name}_messages.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{path}/{channel_name}/{channel_name}_messages.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07777707887784627"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'].isna().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping rt_russian from 161821...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:05 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rt_russian\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_request_x', 'channel_req_targeted_by_x', 'counter_x', 'source_x', 'from_messages_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:35:21 2023\n",
      "\n",
      "\n",
      "Done scraping rt_russian!\n",
      "Scraping ntvnews from 115584...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:22 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> ntvnews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:35:42 2023\n",
      "\n",
      "\n",
      "Done scraping ntvnews!\n",
      "Scraping tvrussia1 from 18678...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:43 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> tvrussia1\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'source_x', 'channel_req_targeted_by_x', 'channel_request_x', 'counter_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:35:49 2023\n",
      "\n",
      "\n",
      "Done scraping tvrussia1!\n",
      "Scraping bbcrussian from 47948...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:50 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> bbcrussian\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:35:56 2023\n",
      "\n",
      "\n",
      "Done scraping bbcrussian!\n",
      "Scraping news_1tv from 21570...\n",
      "\n",
      "Init program at Mon Jul  3 17:35:57 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> news_1tv\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'source_x', 'from_messages_x', 'counter_x', 'channel_request_x', 'channel_req_targeted_by_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:36:11 2023\n",
      "\n",
      "\n",
      "Done scraping news_1tv!\n",
      "Scraping redakciya_channel from 20311...\n",
      "\n",
      "Init program at Mon Jul  3 17:36:12 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> redakciya_channel\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:36:17 2023\n",
      "\n",
      "\n",
      "Done scraping redakciya_channel!\n",
      "Scraping meduzalive from 85602...\n",
      "\n",
      "Init program at Mon Jul  3 17:36:17 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> meduzalive\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'source_x', 'channel_request_x', 'channel_req_targeted_by_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:36:28 2023\n",
      "\n",
      "\n",
      "Done scraping meduzalive!\n",
      "Scraping mediazzzona from 0...\n",
      "\n",
      "Init program at Mon Jul  3 17:36:28 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> mediazzzona\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:38:53 2023\n",
      "\n",
      "\n",
      "Done scraping mediazzzona!\n",
      "Scraping thebell_io from 23281...\n",
      "\n",
      "Init program at Mon Jul  3 17:38:54 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> thebell_io\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'channel_req_targeted_by_x', 'source_x', 'channel_request_x', 'counter_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:38:58 2023\n",
      "\n",
      "\n",
      "Done scraping thebell_io!\n",
      "Scraping rian_ru from 206025...\n",
      "\n",
      "Init program at Mon Jul  3 17:38:59 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rian_ru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:05 2023\n",
      "\n",
      "\n",
      "Done scraping rian_ru!\n",
      "Scraping readovkanews from 60968...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:05 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> readovkanews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'counter_x', 'from_messages_x', 'channel_request_x', 'channel_req_targeted_by_x', 'source_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:13 2023\n",
      "\n",
      "\n",
      "Done scraping readovkanews!\n",
      "Scraping novaya_pishet from 40765...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:14 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> novaya_pishet\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:18 2023\n",
      "\n",
      "\n",
      "Done scraping novaya_pishet!\n",
      "Scraping rbc_news from 76469...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:18 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rbc_news\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_req_targeted_by_x', 'from_messages_x', 'counter_x', 'source_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:27 2023\n",
      "\n",
      "\n",
      "Done scraping rbc_news!\n",
      "Scraping zvezdanews from 121716...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:27 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> zvezdanews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:34 2023\n",
      "\n",
      "\n",
      "Done scraping zvezdanews!\n",
      "Scraping aifonline from 50223...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:34 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> aifonline\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_request_x', 'counter_x', 'channel_req_targeted_by_x', 'from_messages_x', 'source_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:46 2023\n",
      "\n",
      "\n",
      "Done scraping aifonline!\n",
      "Scraping BFMnews from 32214...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:46 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> BFMnews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:50 2023\n",
      "\n",
      "\n",
      "Done scraping BFMnews!\n",
      "Scraping fontankaspb from 40932...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:51 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> fontankaspb\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'channel_req_targeted_by_x', 'source_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:39:56 2023\n",
      "\n",
      "\n",
      "Done scraping fontankaspb!\n",
      "Scraping forbesrussia from 53117...\n",
      "\n",
      "Init program at Mon Jul  3 17:39:57 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> forbesrussia\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:02 2023\n",
      "\n",
      "\n",
      "Done scraping forbesrussia!\n",
      "Scraping gazetaru from 16680...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:03 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> gazetaru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_request_x', 'source_x', 'from_messages_x', 'counter_x', 'channel_req_targeted_by_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:09 2023\n",
      "\n",
      "\n",
      "Done scraping gazetaru!\n",
      "Scraping interfaxonline from 33226...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:09 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> interfaxonline\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:14 2023\n",
      "\n",
      "\n",
      "Done scraping interfaxonline!\n",
      "Scraping izvestia from 134449...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:14 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> izvestia\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'source_x', 'channel_req_targeted_by_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:26 2023\n",
      "\n",
      "\n",
      "Done scraping izvestia!\n",
      "Scraping kommersant from 52082...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:27 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> kommersant\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:34 2023\n",
      "\n",
      "\n",
      "Done scraping kommersant!\n",
      "Scraping lentadnya from 82967...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:35 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> lentadnya\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'channel_req_targeted_by_x', 'source_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:43 2023\n",
      "\n",
      "\n",
      "Done scraping lentadnya!\n",
      "Scraping lifenews from 97755...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:44 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> lifenews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:47 2023\n",
      "\n",
      "\n",
      "Done scraping lifenews!\n",
      "Scraping mk_ru from 33845...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:48 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> mk_ru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_request_x', 'counter_x', 'from_messages_x', 'channel_req_targeted_by_x', 'source_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:40:57 2023\n",
      "\n",
      "\n",
      "Done scraping mk_ru!\n",
      "Scraping novaya_europe from 18929...\n",
      "\n",
      "Init program at Mon Jul  3 17:40:57 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> novaya_europe\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:05 2023\n",
      "\n",
      "\n",
      "Done scraping novaya_europe!\n",
      "Scraping radiosvoboda from 42681...\n",
      "\n",
      "Init program at Mon Jul  3 17:41:05 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> radiosvoboda\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'counter_x', 'channel_request_x', 'source_x', 'channel_req_targeted_by_x', 'from_messages_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:24 2023\n",
      "\n",
      "\n",
      "Done scraping radiosvoboda!\n",
      "Scraping rentv_news from 99623...\n",
      "\n",
      "Init program at Mon Jul  3 17:41:25 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rentv_news\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:34 2023\n",
      "\n",
      "\n",
      "Done scraping rentv_news!\n",
      "Scraping rgrunews from 79290...\n",
      "\n",
      "Init program at Mon Jul  3 17:41:34 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rgrunews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'counter_x', 'channel_req_targeted_by_x', 'from_messages_x', 'source_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:43 2023\n",
      "\n",
      "\n",
      "Done scraping rgrunews!\n",
      "Scraping riafan from 138110...\n",
      "\n",
      "Init program at Mon Jul  3 17:41:44 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> riafan\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:41:58 2023\n",
      "\n",
      "\n",
      "Done scraping riafan!\n",
      "Scraping rusvesnasu from 26800...\n",
      "\n",
      "Init program at Mon Jul  3 17:42:00 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> rusvesnasu\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'from_messages_x', 'counter_x', 'source_x', 'channel_req_targeted_by_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:42:08 2023\n",
      "\n",
      "\n",
      "Done scraping rusvesnasu!\n",
      "Scraping svpressaru from 19835...\n",
      "\n",
      "Init program at Mon Jul  3 17:42:09 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> svpressaru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:42:13 2023\n",
      "\n",
      "\n",
      "Done scraping svpressaru!\n",
      "Scraping tass_agency from 196757...\n",
      "\n",
      "Init program at Mon Jul  3 17:42:13 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> tass_agency\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327,336,337) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'channel_req_targeted_by_x', 'channel_request_x', 'counter_x', 'source_x', 'from_messages_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:42:36 2023\n",
      "\n",
      "\n",
      "Done scraping tass_agency!\n",
      "Scraping truekpru from 123477...\n",
      "\n",
      "Init program at Mon Jul  3 17:42:37 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> truekpru\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327,336,337) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:43:03 2023\n",
      "\n",
      "\n",
      "Done scraping truekpru!\n",
      "Scraping uranews from 76922...\n",
      "\n",
      "Init program at Mon Jul  3 17:43:04 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> uranews\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n",
      "> Writing posts data...\n",
      "> done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:381: DtypeWarning: Columns (36,37,41,42,46,47,51,52,56,57,61,62,66,67,71,72,76,77,81,82,86,87,91,92,96,97,101,102,106,107,111,112,116,117,121,122,126,127,131,132,136,137,141,142,146,147,151,152,156,157,161,162,166,167,196,197,211,212,236,237,241,242,251,252,256,257,261,262,266,267,271,272,276,277,286,287,296,297,306,307,321,322,326,327,336,337) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/main.py:387: FutureWarning: Passing 'suffixes' which cause duplicate columns {'source_x', 'channel_req_targeted_by_x', 'from_messages_x', 'counter_x', 'channel_request_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = df.merge(counter_df, how='left', on='id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End program at Mon Jul  3 17:43:09 2023\n",
      "\n",
      "\n",
      "Done scraping uranews!\n",
      "Scraping vedomosti from 0...\n",
      "\n",
      "Init program at Mon Jul  3 17:43:10 2023\n",
      "\n",
      "\n",
      "> Authorized!\n",
      "\n",
      "> Collecting data from Telegram Channel -> vedomosti\n",
      "> ...\n",
      "\n",
      "> Writing channel data...\n",
      "> done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load csv_channels\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# path to json folders\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "\n",
    "# download new messages for each channel\n",
    "for i, row in df_channels.iterrows():\n",
    "    last_id = int(row['last_id']) if not np.isnan(row['last_id']) else 0\n",
    "    channel_name = row['channel_name']\n",
    "    # run scraper for each channel\n",
    "    print(f\"Scraping {channel_name} from {last_id}...\")\n",
    "    os.system(f\"python3 main.py --telegram-channel {channel_name} --min-id {last_id} -o {path} > download_log.txt\")\n",
    "    print(f\"Done scraping {channel_name}!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-load processing (convert json to csv & store last_id into channels.csv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking last_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_50407/908211125.py:4: DtypeWarning: Columns (11,13,14,15,21,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csv = pd.read_csv(f\"{path}/{channel_name}/{channel_name}_messages.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "# check that last_id in channels.csv, json and csv are the same\n",
    "channel_name = 'lentadnya'\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "df_csv = pd.read_csv(f\"{path}/{channel_name}/{channel_name}_messages.csv\", index_col=0)\n",
    "with open(f'{path}/{channel_name}/{channel_name}_messages.json') as f:\n",
    "    data = json.load(f)\n",
    "    df_json = pd.DataFrame.from_dict(data['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv['id'].max() == df_json['id'].min() == df_channels[df_channels['channel_name'] == channel_name]['last_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82967, 82967, nan)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels = pd.read_csv('channels.csv')\n",
    "df_csv['id'].max(), df_json['id'].max(), df_channels[df_channels['channel_name'] == channel_name]['last_id'].values[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean texts, remvove NaN, json2csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis_and_links(text):\n",
    "    # Unicode range for emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                               \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "                               \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "                               \"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    # Regular expression for URLs\n",
    "    url_pattern = re.compile(r\"http\\S+|www\\S+\")\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = url_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove any remaining variation selectors\n",
    "    text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')\n",
    "\n",
    "    #Remove Foreign Agent text\n",
    "    ino_text1 = '  \\(\\)   \\(\\)     ,    ,  \\(\\)   ,    '\n",
    "    ino_text2 = '  \\(\\)      THE BELL     '\n",
    "    for ino_text in [ino_text1, ino_text2]:\n",
    "        text = text.replace(ino_text, '')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvc_ru csv created\n",
      "tsargradtv csv created\n",
      "strelkovii csv created\n",
      "concordgroup_official csv created\n",
      "Missing folders: []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m         missing_folders\u001b[39m.\u001b[39mappend(channel_name)\n\u001b[1;32m     68\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing folders: \u001b[39m\u001b[39m{\u001b[39;00mmissing_folders\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m df_channels\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39m\u001b[39mchannels.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m df_stat\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mstat.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlast_id in channels.csv updated, df_stat.csv saved\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# load channels (from file or list)\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# df_channels = ['tvc_ru', 'tsargradtv', 'strelkovii', 'concordgroup_official']\n",
    "\n",
    "# toggle remove_duplicates\n",
    "remove_duplicates = True\n",
    "\n",
    "# path to json folders (till data folder)\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "missing_folders = []\n",
    "start_time = time.time()\n",
    "df_stat = pd.DataFrame()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# convert json files to csv & update last_id\n",
    "# for i, row in tqdm(df_channels.iterrows(), total=df_channels.shape[0]):\n",
    "for i, row in enumerate(df_channels):\n",
    "    if isinstance(df_channels, pd.DataFrame):\n",
    "        channel_name = row['channel_name']\n",
    "        channel_id = df_new.peer_id[0]['channel_id']\n",
    "        ignore = row['ignore']\n",
    "    else: \n",
    "        channel_name = row\n",
    "        channel_id = None\n",
    "        ignore = None\n",
    "    # add channel_name to df_stat\n",
    "    df_stat.loc[i, 'channel_name'] = channel_name\n",
    "    # check if channel_name exists in the folder or marked as ignore\n",
    "    if os.path.exists(f'{path}/{channel_name}') and not ignore=='y':\n",
    "        # read json file & find the last message id\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.json') as f:\n",
    "            data = json.load(f)\n",
    "            df_new = pd.DataFrame.from_dict(data['messages'])\n",
    "            # constants\n",
    "            df_new['channel_id'] = channel_id\n",
    "            df_new['channel_name'] = channel_name\n",
    "            # find the last id\n",
    "            last_id = max(df_new['id'])\n",
    "            df_stat.loc[i, 'last_id'] = last_id\n",
    "            df_stat.loc[i, 'N_new_messages'] = df_new.shape[0]\n",
    "        # remove messages with NaN & digests\n",
    "        df_new = df_new[~df_new['message'].isna()]\n",
    "        digest_filter = ' |  | |  |  '\n",
    "        df_new = df_new[~df_new['message'].str.contains(digest_filter)]\n",
    "        # clean text\n",
    "        df_new['cleaned_message'] = df_new['message'].apply(lambda x: remove_emojis_and_links(x))\n",
    "        \n",
    "        # update csv-database with new messages\n",
    "        csv_path = f'{path}/{channel_name}/{channel_name}_messages.csv'\n",
    "        \n",
    "        # check if csv exists\n",
    "        if not os.path.exists(csv_path):\n",
    "            df_new.to_csv(csv_path)\n",
    "            print(f\"{channel_name} csv created\")\n",
    "        else:\n",
    "            with open(csv_path) as c:\n",
    "                df = pd.read_csv(c, index_col=0)\n",
    "                # add new rows from df_new\n",
    "                df = df.append(df_new, ignore_index=True)\n",
    "                # remove duplicates\n",
    "                if remove_duplicates:\n",
    "                    df = df.drop_duplicates(subset=['id'])\n",
    "                df.to_csv(csv_path)\n",
    "        \n",
    "        # update last_id (for channels.csv)\n",
    "        # df_channels.loc[i, 'last_id'] = last_id\n",
    "        finish_time = time.time()\n",
    "        df_stat.loc[i, 'time'] = round(finish_time - start_time, 2)\n",
    "        start_time = finish_time\n",
    "    else:\n",
    "        missing_folders.append(channel_name)\n",
    "\n",
    "print(f\"Missing folders: {missing_folders}\")\n",
    "if isinstance(df_channels, pd.DataFrame):\n",
    "    df_channels.to_csv('channels.csv', index=False)\n",
    "df_stat.to_csv('stat.csv', index=False)\n",
    "print(\"last_id in channels.csv updated, df_stat.csv saved\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/3938672430.py:1: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data/aifonline/aifonline_messages.csv', index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data/aifonline/aifonline_messages.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  48%|     | 914/1887 [39:58<42:32,  2.62s/it]\n",
      "0it [40:01, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(f, usecols\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcleaned_message\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m \u001b[39m# calculate embeddings & save to numpy\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m embeddings \u001b[39m=\u001b[39m sentence_model\u001b[39m.\u001b[39;49mencode(df[\u001b[39m'\u001b[39;49m\u001b[39mcleaned_message\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist(), show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     21\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mchannel_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mchannel_name\u001b[39m}\u001b[39;00m\u001b[39m_embeddings.npy\u001b[39m\u001b[39m'\u001b[39m, embeddings)\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mchannel_name\u001b[39m}\u001b[39;00m\u001b[39m embeddings saved\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:853\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    844\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    846\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    847\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    848\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    852\u001b[0m )\n\u001b[0;32m--> 853\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    854\u001b[0m     embedding_output,\n\u001b[1;32m    855\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    856\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    857\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    858\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    859\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    860\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    861\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    862\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    863\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    864\u001b[0m )\n\u001b[1;32m    865\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    866\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:527\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    518\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    520\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    528\u001b[0m         hidden_states,\n\u001b[1;32m    529\u001b[0m         attention_mask,\n\u001b[1;32m    530\u001b[0m         layer_head_mask,\n\u001b[1;32m    531\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    532\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    533\u001b[0m         past_key_value,\n\u001b[1;32m    534\u001b[0m         output_attentions,\n\u001b[1;32m    535\u001b[0m     )\n\u001b[1;32m    537\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:454\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    451\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    452\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 454\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    455\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    456\u001b[0m )\n\u001b[1;32m    457\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    459\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/transformers/pytorch_utils.py:249\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 249\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:467\u001b[0m, in \u001b[0;36mXLMRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m    466\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 467\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    468\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:378\u001b[0m, in \u001b[0;36mXLMRobertaOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 378\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    379\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    380\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# NEED TO CHECK WHICH EMBEDDINGS ARE ALREADY CALCULATED & UPDATE ONLY MISSING ONES\n",
    "\n",
    "# load channels (from file or list)\n",
    "df_channels = pd.read_csv('channels.csv', usecols=['channel_name'], squeeze=True)\n",
    "channels = df_channels.to_list()\n",
    "\n",
    "missing_channels = []\n",
    "\n",
    "# calculate embeddings for all csv files\n",
    "# sentence_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\") # a bit faster, less precise\n",
    "sentence_model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\") # a bit slower, more precise\n",
    "\n",
    "for i, channel_name in tqdm(enumerate(channels)):\n",
    "    # if csv does not exists - skip and store channel_name\n",
    "    if not os.path.exists(f'{path}/{channel_name}/{channel_name}_messages.csv'):\n",
    "        missing_channels.append(channel_name)\n",
    "    else:\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.csv') as f:\n",
    "            df = pd.read_csv(f, usecols=['cleaned_message'])\n",
    "            # calculate embeddings & save to numpy\n",
    "            embeddings = sentence_model.encode(df['cleaned_message'].tolist(), show_progress_bar=True)\n",
    "            np.save(f'{path}/{channel_name}/{channel_name}_embeddings.npy', embeddings)\n",
    "            print(f'{i} {channel_name} embeddings saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE-TIME PROCEDURES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clean messages -> col 'cleaned_message'\n",
    "2. Remove NaN and digests\n",
    "3. Update last_id in channels.csv\n",
    "4. Link embeddings with csv databases\n",
    "5. Remove doublicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rt_russian last: 164235\n",
      "Time elapsed: 4.94 seconds\n",
      "1 ntvnews last: 116705\n",
      "Time elapsed: 0.09 seconds\n",
      "2 tvrussia1 last: 19538\n",
      "Time elapsed: 0.11 seconds\n",
      "3 bbcrussian last: 48798\n",
      "Time elapsed: 0.08 seconds\n",
      "4 news_1tv last: 22056\n",
      "Time elapsed: 0.03 seconds\n",
      "5 redakciya_channel last: 21152\n",
      "Time elapsed: 0.04 seconds\n",
      "6 meduzalive last: 87152\n",
      "Time elapsed: 0.2 seconds\n",
      "7 mediazzzona last: 12101\n",
      "Time elapsed: 2.25 seconds\n",
      "8 thebell_io last: 23585\n",
      "Time elapsed: 0.1 seconds\n",
      "9 rian_ru last: 207734\n",
      "Time elapsed: 0.04 seconds\n",
      "10 readovkanews last: 61903\n",
      "Time elapsed: 0.07 seconds\n",
      "11 novaya_pishet last: 41023\n",
      "Time elapsed: 0.02 seconds\n",
      "12 rbc_news last: 77596\n",
      "Time elapsed: 0.07 seconds\n",
      "13 zvezdanews last: 123306\n",
      "Time elapsed: 0.06 seconds\n",
      "14 aifonline last: 52411\n",
      "Time elapsed: 0.19 seconds\n",
      "15 BFMnews last: 32808\n",
      "Time elapsed: 0.03 seconds\n",
      "16 fontankaspb last: 41786\n",
      "Time elapsed: 0.04 seconds\n",
      "17 forbesrussia last: 53822\n",
      "Time elapsed: 0.03 seconds\n",
      "18 gazetaru last: 17701\n",
      "Time elapsed: 0.08 seconds\n",
      "19 interfaxonline last: 33741\n",
      "Time elapsed: 0.02 seconds\n",
      "20 izvestia last: 135989\n",
      "Time elapsed: 0.05 seconds\n",
      "21 kommersant last: 52863\n",
      "Time elapsed: 0.05 seconds\n",
      "22 lentadnya last: 84585\n",
      "Time elapsed: 0.11 seconds\n",
      "23 lifenews last: 98004\n",
      "Time elapsed: 0.02 seconds\n",
      "24 mk_ru last: 35368\n",
      "Time elapsed: 0.05 seconds\n",
      "25 novaya_europe last: 19900\n",
      "Time elapsed: 0.13 seconds\n",
      "26 radiosvoboda last: 43601\n",
      "Time elapsed: 0.07 seconds\n",
      "27 rentv_news last: 101468\n",
      "Time elapsed: 0.1 seconds\n",
      "28 rgrunews last: 80629\n",
      "Time elapsed: 0.06 seconds\n",
      "29 riafan last: 139454\n",
      "Time elapsed: 0.06 seconds\n",
      "30 rusvesnasu last: 27048\n",
      "Time elapsed: 0.02 seconds\n",
      "31 svpressaru last: 20000\n",
      "Time elapsed: 0.05 seconds\n",
      "32 tass_agency last: 199324\n",
      "Time elapsed: 0.09 seconds\n",
      "33 truekpru last: 124717\n",
      "Time elapsed: 0.12 seconds\n",
      "34 uranews last: 77603\n",
      "Time elapsed: 0.04 seconds\n",
      "35 vedomosti last: 34033\n",
      "Time elapsed: 3.44 seconds\n",
      "36 vestiru24 last: 78732\n",
      "Time elapsed: 3.63 seconds\n",
      "37 tsargradtv last: 49015\n",
      "Time elapsed: 6.26 seconds\n",
      "38 sashakots last: 40743\n",
      "Time elapsed: 0.28 seconds\n",
      "39 rybar last: 49285\n",
      "Time elapsed: 0.04 seconds\n",
      "40 voenacher last: 47737\n",
      "Time elapsed: 0.06 seconds\n",
      "41 vysokygovorit last: 12163\n",
      "Time elapsed: 0.01 seconds\n",
      "42 SolovievLive last: 192455\n",
      "Time elapsed: 0.18 seconds\n",
      "43 margaritasimonyan last: 13079\n",
      "Time elapsed: 0.02 seconds\n",
      "44 breakingmash last: 45597\n",
      "Time elapsed: 0.02 seconds\n",
      "45 tvc_ru last: 55158\n",
      "Time elapsed: 2.69 seconds\n",
      "46 strelkovii last: 5858\n",
      "Time elapsed: 0.45 seconds\n",
      "47 concordgroup_official last: 1304\n",
      "Time elapsed: 0.08 seconds\n",
      "Missing folders: []\n",
      "last_id updated\n"
     ]
    }
   ],
   "source": [
    "# ONLY UPDATE LAST_ID in csv_channels\n",
    "\n",
    "# load csv_channels\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# path to json folders\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "\n",
    "missing_folders = []\n",
    "\n",
    "start_time = time.time()\n",
    "# iterate over rows, set last_id and show missing folders\n",
    "for i, row in df_channels.iterrows():\n",
    "    channel_name = row['channel_name']\n",
    "    # set last_id to 0\n",
    "    row['last_id'] = 0\n",
    "    # check channel_name exists in the folder\n",
    "    if os.path.exists(f'{path}/{channel_name}'):\n",
    "        # read json file & find the last message id\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.json') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame.from_dict(data['messages'])\n",
    "            last_id = max(df['id'])\n",
    "            # update channels csv\n",
    "            df_channels.loc[i, 'last_id'] = last_id\n",
    "        print(f'{i} {channel_name} last: {last_id}')\n",
    "    else:\n",
    "        missing_folders.append(channel_name)\n",
    "    finish_time = time.time()\n",
    "    print(f\"Time elapsed: {round(finish_time - start_time, 2)} seconds\")\n",
    "    start_time = finish_time\n",
    "print(f\"Missing folders: {missing_folders}\")\n",
    "df_channels.to_csv('channels.csv', index=False)\n",
    "print(\"last_id updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "  2%|         | 1/48 [00:15<12:06, 15.46s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (17,19,21,25,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "  6%|         | 3/48 [00:30<06:29,  8.65s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (17,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "  8%|         | 4/48 [00:49<09:23, 12.80s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (19,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 12%|        | 6/48 [00:57<05:26,  7.78s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (21,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 17%|        | 8/48 [01:42<09:21, 14.03s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (25,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 19%|        | 9/48 [01:50<07:51, 12.10s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,17,21,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 21%|        | 10/48 [02:05<08:15, 13.05s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,21,27,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 23%|       | 11/48 [02:19<08:08, 13.22s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 25%|       | 12/48 [02:28<07:08, 11.90s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (21,25,27,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 27%|       | 13/48 [02:47<08:19, 14.28s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (17,21,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 29%|       | 14/48 [03:09<09:21, 16.51s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (21,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 31%|      | 15/48 [03:23<08:36, 15.66s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (21,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 33%|      | 16/48 [03:29<06:53, 12.93s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (27,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 35%|      | 17/48 [03:39<06:06, 11.81s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (21,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 38%|      | 18/48 [03:48<05:29, 10.98s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (17,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 40%|      | 19/48 [03:52<04:20,  8.97s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (17,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 42%|     | 20/48 [03:58<03:46,  8.10s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,17,19,21,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 44%|     | 21/48 [04:13<04:36, 10.25s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,21,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 46%|     | 22/48 [04:24<04:33, 10.53s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,21,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 48%|     | 23/48 [04:34<04:13, 10.14s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,17,19,21,25,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 50%|     | 24/48 [04:44<04:04, 10.18s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (21,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 52%|    | 25/48 [04:50<03:25,  8.92s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (21,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 54%|    | 26/48 [04:58<03:07,  8.54s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 56%|    | 27/48 [05:22<04:37, 13.22s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,29,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 58%|    | 28/48 [05:50<05:57, 17.86s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,21,25,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 60%|    | 29/48 [06:22<06:54, 21.82s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,19,21,25,29,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 62%|   | 30/48 [06:45<06:39, 22.21s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 65%|   | 31/48 [06:50<04:50, 17.09s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (19,21,25,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 67%|   | 32/48 [06:56<03:41, 13.85s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,17,21,25,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 69%|   | 33/48 [07:28<04:49, 19.29s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (21,25,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 71%|   | 34/48 [07:55<05:03, 21.65s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (11,13,14,15,21,25,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 73%|  | 35/48 [08:13<04:26, 20.53s/it]/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_70021/1473799604.py:15: DtypeWarning: Columns (19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      " 75%|  | 36/48 [08:22<02:47, 13.95s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data/vestiru24/vestiru24_messages.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# check if channel_name exists in the folder or marked as ignore\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mchannel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m row[\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mpath\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mchannel_name\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mchannel_name\u001b[39m}\u001b[39;49;00m\u001b[39m_messages.csv\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     15\u001b[0m         df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(f)\n\u001b[1;32m     16\u001b[0m         \u001b[39m# remove messages with NaN & digests\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/bertopic/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data/vestiru24/vestiru24_messages.csv'"
     ]
    }
   ],
   "source": [
    "# CLEAN TEXT IN ALL CSV FILES\n",
    "# load csv_channels\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# path to json folders\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "\n",
    "# clean messages\n",
    "for i, row in tqdm(df_channels.iterrows(), total=df_channels.shape[0]):\n",
    "    channel_name = row['channel_name']\n",
    "    # set last_id to 0\n",
    "    row['last_id'] = 0\n",
    "    # check if channel_name exists in the folder or marked as ignore\n",
    "    if os.path.exists(f'{path}/{channel_name}') and not row['ignore']=='y':\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.csv') as f:\n",
    "            df = pd.read_csv(f)\n",
    "            # remove messages with NaN & digests\n",
    "            df = df[~df['message'].isna()]\n",
    "            digest_filter = ' |  | |  |  '\n",
    "            df = df[~df['message'].str.contains(digest_filter)]\n",
    "            if 'Unnamed: 0' in df.columns: df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "            # clean text\n",
    "            df['cleaned_message'] = df['message'].apply(lambda x: remove_emojis_and_links(x))\n",
    "        # update csv-database with cleaned messages\n",
    "        df.to_csv(f'{path}/{channel_name}/{channel_name}_messages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Database - OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/jtb7c8xn51902fgjqt4qh5h80000gp/T/ipykernel_57367/4121249504.py:1: DtypeWarning: Columns (14,16,17,18,19,22,26,27,28,29,30,33,35,37,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_messages = pd.read_csv('/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/output/data/msgs_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "df_messages = pd.read_csv('/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/output/data/msgs_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 992K messages\n",
      "N of channels 11\n"
     ]
    }
   ],
   "source": [
    "print(f\"The file contains {round(df_messages.shape[0]/1000)}K messages\")\n",
    "print(f\"N of channels {df_messages['channel_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rt_russian           316770\n",
       "rian_ru              204610\n",
       "meduzalive           169360\n",
       "ntvnews              113920\n",
       "readovkanews          59745\n",
       "bbcrussian            46656\n",
       "thebell_io            22537\n",
       "news_1tv              21236\n",
       "redakciya_channel     19167\n",
       "tvrussia1             18105\n",
       "tchantest               168\n",
       "Name: channel_name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages['channel_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rt_russian    158051\n",
       "meduzalive     84680\n",
       "tchantest         84\n",
       "Name: channel_name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages['channel_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['signature', 'channel_id', 'channel_name', 'msg_id', 'message',\n",
       "       'cleaned_message', 'date', 'msg_link', 'msg_from_peer', 'msg_from_id',\n",
       "       'views', 'number_replies', 'number_forwards', 'is_forward',\n",
       "       'forward_msg_from_peer_type', 'forward_msg_from_peer_id',\n",
       "       'forward_msg_from_peer_name', 'forward_msg_date',\n",
       "       'forward_msg_date_string', 'forward_msg_link', 'is_reply',\n",
       "       'reply_to_msg_id', 'reply_msg_link', 'contains_media', 'media_type',\n",
       "       'has_url', 'url', 'domain', 'url_title', 'url_description',\n",
       "       'document_type', 'document_id', 'document_video_duration',\n",
       "       'document_filename', 'poll_id', 'poll_question', 'poll_total_voters',\n",
       "       'poll_results', 'contact_phone_number', 'contact_name',\n",
       "       'contact_userid', 'geo_type', 'lat', 'lng', 'venue_id', 'venue_type',\n",
       "       'venue_title', 'venue_address', 'venue_provider'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messages['date'] = pd.to_datetime(df_messages['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>msg_id</th>\n",
       "      <th>message</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158135</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85602</td>\n",
       "      <td>      ...</td>\n",
       "      <td>2023-06-10 15:01:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158136</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85601</td>\n",
       "      <td>    ...</td>\n",
       "      <td>2023-06-10 14:49:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158137</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85600</td>\n",
       "      <td>       ...</td>\n",
       "      <td>2023-06-10 14:28:35+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158138</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85599</td>\n",
       "      <td>     ...</td>\n",
       "      <td>2023-06-10 14:02:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158139</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>85598</td>\n",
       "      <td>   .    ...</td>\n",
       "      <td>2023-06-10 13:50:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206864</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36414</td>\n",
       "      <td>   ?  ,    1 ...</td>\n",
       "      <td>2021-01-01 10:00:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206865</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36413</td>\n",
       "      <td>,     :  ...</td>\n",
       "      <td>2021-01-01 09:49:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206866</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36412</td>\n",
       "      <td>  ,      ...</td>\n",
       "      <td>2021-01-01 08:49:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206867</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36411</td>\n",
       "      <td>\\n      ,  ...</td>\n",
       "      <td>2021-01-01 07:49:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206868</th>\n",
       "      <td>meduzalive</td>\n",
       "      <td>36410</td>\n",
       "      <td>      ...</td>\n",
       "      <td>2021-01-01 06:49:50+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48734 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel_name  msg_id  \\\n",
       "158135   meduzalive   85602   \n",
       "158136   meduzalive   85601   \n",
       "158137   meduzalive   85600   \n",
       "158138   meduzalive   85599   \n",
       "158139   meduzalive   85598   \n",
       "...             ...     ...   \n",
       "206864   meduzalive   36414   \n",
       "206865   meduzalive   36413   \n",
       "206866   meduzalive   36412   \n",
       "206867   meduzalive   36411   \n",
       "206868   meduzalive   36410   \n",
       "\n",
       "                                                  message  \\\n",
       "158135        ...   \n",
       "158136      ...   \n",
       "158137         ...   \n",
       "158138       ...   \n",
       "158139     .    ...   \n",
       "...                                                   ...   \n",
       "206864     ?  ,    1 ...   \n",
       "206865  ,     :  ...   \n",
       "206866    ,      ...   \n",
       "206867  \\n      ,  ...   \n",
       "206868        ...   \n",
       "\n",
       "                            date  \n",
       "158135 2023-06-10 15:01:23+00:00  \n",
       "158136 2023-06-10 14:49:01+00:00  \n",
       "158137 2023-06-10 14:28:35+00:00  \n",
       "158138 2023-06-10 14:02:10+00:00  \n",
       "158139 2023-06-10 13:50:01+00:00  \n",
       "...                          ...  \n",
       "206864 2021-01-01 10:00:16+00:00  \n",
       "206865 2021-01-01 09:49:50+00:00  \n",
       "206866 2021-01-01 08:49:50+00:00  \n",
       "206867 2021-01-01 07:49:50+00:00  \n",
       "206868 2021-01-01 06:49:50+00:00  \n",
       "\n",
       "[48734 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages[(df_messages['channel_name'] == 'meduzalive') & (df_messages['date'] > utc.localize(datetime(year=2021, month=1, day=1)))][['channel_name', 'msg_id', 'message', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime64[ns, UTC]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_messages['date'].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## via json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rt_russian last: 161821\n",
      "Time elapsed: 18.83 seconds\n",
      "1 ntvnews last: 115584\n",
      "Time elapsed: 13.87 seconds\n",
      "2 tvrussia1 last: 18678\n",
      "Time elapsed: 0.96 seconds\n",
      "3 bbcrussian last: 47948\n",
      "Time elapsed: 6.33 seconds\n",
      "4 news_1tv last: 21570\n",
      "Time elapsed: 1.0 seconds\n",
      "5 redakciya_channel last: 20311\n",
      "Time elapsed: 2.03 seconds\n",
      "6 meduzalive last: 85602\n",
      "Time elapsed: 35.3 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "8 thebell_io last: 23281\n",
      "Time elapsed: 3.46 seconds\n",
      "9 rian_ru last: 206025\n",
      "Time elapsed: 7.18 seconds\n",
      "10 readovkanews last: 60968\n",
      "Time elapsed: 5.4 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Time elapsed: 0.0 seconds\n",
      "Missing folders: ['mediazzzona', 'novaya_pishet', 'rbc_news', 'zvezdanews', 'aifonline', 'BFMnews', 'fontankaspb', 'forbesrussia', 'gazetaru', 'interfaxonline', 'izvestia', 'kommersant', 'lentadnya', 'lifenews', 'mk_ru', 'novaya_europe', 'radiosvoboda', 'rentv_news', 'rgrunews', 'riafan', 'rusvesnasu', 'svpressaru', 'tass_agency', 'truekpru', 'uranews', 'vedomosti', 'vestiru24', 'tsargradtv', 'sashakots', 'rybar', 'voenacher', 'vysokygovorit', 'SolovievLive', 'margaritasimonyan', 'breakingmash', 'tvc_ru']\n",
      "last_id updated\n"
     ]
    }
   ],
   "source": [
    "# ONLY UPDATE LAST_ID in csv_channels\n",
    "\n",
    "# load csv_channels\n",
    "df_channels = pd.read_csv('channels.csv')\n",
    "# path to json folders\n",
    "path = '/Volumes/netac/Politics_economy/_news_narratives/TG_scraping/telegram-tracker/output/data'\n",
    "\n",
    "missing_folders = []\n",
    "\n",
    "start_time = time.time()\n",
    "# iterate over rows, set last_id and show missing folders\n",
    "for i, row in df_channels.iterrows():\n",
    "    channel_name = row['channel_name']\n",
    "    # set last_id to 0\n",
    "    row['last_id'] = 0\n",
    "    # check channel_name exists in the folder\n",
    "    if os.path.exists(f'{path}/{channel_name}'):\n",
    "        # read json file & find the last message id\n",
    "        with open(f'{path}/{channel_name}/{channel_name}_messages.json') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame.from_dict(data['messages'])\n",
    "            last_id = max(df['id'])\n",
    "            # update channels csv\n",
    "            df_channels.loc[i, 'last_id'] = last_id\n",
    "        print(f'{i} {channel_name} last: {last_id}')\n",
    "    else:\n",
    "        missing_folders.append(channel_name)\n",
    "    finish_time = time.time()\n",
    "    print(f\"Time elapsed: {round(finish_time - start_time, 2)} seconds\")\n",
    "    start_time = finish_time\n",
    "print(f\"Missing folders: {missing_folders}\")\n",
    "df_channels.to_csv('channels.csv', index=False)\n",
    "print(\"last_id updated\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file\n",
    "with open('/Users/oslikdau/in_progress/_news narratives/TG scraping/telegram-tracker/output/data/bbcrussian/bbcrussian_messages.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_', 'pts', 'count', 'messages', 'topics', 'chats', 'users', 'inexact', 'offset_id_offset'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert json to dataframe\n",
    "df = pd.DataFrame.from_dict(data['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_', 'id', 'peer_id', 'date', 'message', 'out', 'mentioned',\n",
       "       'media_unread', 'silent', 'post', 'from_scheduled', 'legacy',\n",
       "       'edit_hide', 'pinned', 'noforwards', 'from_id', 'fwd_from',\n",
       "       'via_bot_id', 'reply_to', 'media', 'reply_markup', 'entities', 'views',\n",
       "       'forwards', 'replies', 'edit_date', 'post_author', 'grouped_id',\n",
       "       'reactions', 'restriction_reason', 'ttl_period', 'action'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 0.0024161303427484015)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# share of NaN messages\n",
    "df['message'].isna().sum(), df['message'].isna().sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47948"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the last message id\n",
    "max(df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>id</th>\n",
       "      <th>peer_id</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>out</th>\n",
       "      <th>mentioned</th>\n",
       "      <th>media_unread</th>\n",
       "      <th>silent</th>\n",
       "      <th>post</th>\n",
       "      <th>...</th>\n",
       "      <th>views</th>\n",
       "      <th>forwards</th>\n",
       "      <th>replies</th>\n",
       "      <th>edit_date</th>\n",
       "      <th>post_author</th>\n",
       "      <th>grouped_id</th>\n",
       "      <th>reactions</th>\n",
       "      <th>restriction_reason</th>\n",
       "      <th>ttl_period</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Message</td>\n",
       "      <td>47947</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 16:43:34+00:00</td>\n",
       "      <td>       ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>20108.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Message</td>\n",
       "      <td>47946</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 16:27:18+00:00</td>\n",
       "      <td> : 23 ,   ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>25015.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Message</td>\n",
       "      <td>47942</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 14:30:12+00:00</td>\n",
       "      <td> 478  .  ,  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>44689.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-16 15:46:15+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Message</td>\n",
       "      <td>47935</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 11:40:57+00:00</td>\n",
       "      <td>\"   \".   ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>54462.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-16 12:10:27+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Message</td>\n",
       "      <td>47923</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2023-06-16 07:54:27+00:00</td>\n",
       "      <td>     28   ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>76994.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46426</th>\n",
       "      <td>Message</td>\n",
       "      <td>356</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2016-09-15 10:06:16+00:00</td>\n",
       "      <td> !      :...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46522</th>\n",
       "      <td>Message</td>\n",
       "      <td>256</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2016-05-30 10:49:45+00:00</td>\n",
       "      <td>,    :\\n ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-30 10:50:04+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46531</th>\n",
       "      <td>Message</td>\n",
       "      <td>247</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2016-05-19 11:28:54+00:00</td>\n",
       "      <td>     ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-19 11:29:08+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46631</th>\n",
       "      <td>Message</td>\n",
       "      <td>146</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2016-02-17 08:58:44+00:00</td>\n",
       "      <td>,    . \\n\\n ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46742</th>\n",
       "      <td>Message</td>\n",
       "      <td>30</td>\n",
       "      <td>{'_': 'PeerChannel', 'channel_id': 1003921752}</td>\n",
       "      <td>2015-12-09 18:44:28+00:00</td>\n",
       "      <td> \"   \".  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-13 16:32:01+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8344 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             _     id                                         peer_id  \\\n",
       "1      Message  47947  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "2      Message  47946  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "6      Message  47942  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "13     Message  47935  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "25     Message  47923  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "...        ...    ...                                             ...   \n",
       "46426  Message    356  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "46522  Message    256  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "46531  Message    247  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "46631  Message    146  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "46742  Message     30  {'_': 'PeerChannel', 'channel_id': 1003921752}   \n",
       "\n",
       "                            date  \\\n",
       "1      2023-06-16 16:43:34+00:00   \n",
       "2      2023-06-16 16:27:18+00:00   \n",
       "6      2023-06-16 14:30:12+00:00   \n",
       "13     2023-06-16 11:40:57+00:00   \n",
       "25     2023-06-16 07:54:27+00:00   \n",
       "...                          ...   \n",
       "46426  2016-09-15 10:06:16+00:00   \n",
       "46522  2016-05-30 10:49:45+00:00   \n",
       "46531  2016-05-19 11:28:54+00:00   \n",
       "46631  2016-02-17 08:58:44+00:00   \n",
       "46742  2015-12-09 18:44:28+00:00   \n",
       "\n",
       "                                                 message    out  mentioned  \\\n",
       "1             ...  False      False   \n",
       "2       : 23 ,   ...  False      False   \n",
       "6       478  .  ,  ...  False      False   \n",
       "13     \"   \".   ...  False      False   \n",
       "25          28   ...  False      False   \n",
       "...                                                  ...    ...        ...   \n",
       "46426   !      :...  False      False   \n",
       "46522  ,    :\\n ...  False      False   \n",
       "46531       ...  False      False   \n",
       "46631  ,    . \\n\\n ...  False      False   \n",
       "46742   \"   \".  ...  False      False   \n",
       "\n",
       "       media_unread  silent  post  ...    views  forwards replies  \\\n",
       "1             False   False  True  ...  20108.0      10.0     NaN   \n",
       "2             False   False  True  ...  25015.0      22.0     NaN   \n",
       "6             False   False  True  ...  44689.0      11.0     NaN   \n",
       "13            False   False  True  ...  54462.0     106.0     NaN   \n",
       "25            False   False  True  ...  76994.0     223.0     NaN   \n",
       "...             ...     ...   ...  ...      ...       ...     ...   \n",
       "46426         False   False  True  ...   2757.0       0.0     NaN   \n",
       "46522         False   False  True  ...   2050.0       0.0     NaN   \n",
       "46531         False   False  True  ...   2683.0       0.0     NaN   \n",
       "46631         False   False  True  ...   1730.0       0.0     NaN   \n",
       "46742         False   False  True  ...   1270.0       1.0     NaN   \n",
       "\n",
       "                       edit_date post_author grouped_id reactions  \\\n",
       "1                           None         NaN        NaN       NaN   \n",
       "2                           None         NaN        NaN       NaN   \n",
       "6      2023-06-16 15:46:15+00:00         NaN        NaN       NaN   \n",
       "13     2023-06-16 12:10:27+00:00         NaN        NaN       NaN   \n",
       "25                          None         NaN        NaN       NaN   \n",
       "...                          ...         ...        ...       ...   \n",
       "46426                       None         NaN        NaN       NaN   \n",
       "46522  2016-05-30 10:50:04+00:00         NaN        NaN       NaN   \n",
       "46531  2016-05-19 11:29:08+00:00         NaN        NaN       NaN   \n",
       "46631                       None         NaN        NaN       NaN   \n",
       "46742  2022-06-13 16:32:01+00:00         NaN        NaN       NaN   \n",
       "\n",
       "       restriction_reason ttl_period action  \n",
       "1                      []       None    NaN  \n",
       "2                      []       None    NaN  \n",
       "6                      []       None    NaN  \n",
       "13                     []       None    NaN  \n",
       "25                     []       None    NaN  \n",
       "...                   ...        ...    ...  \n",
       "46426                  []       None    NaN  \n",
       "46522                  []       None    NaN  \n",
       "46531                  []       None    NaN  \n",
       "46631                  []       None    NaN  \n",
       "46742                  []       None    NaN  \n",
       "\n",
       "[8344 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keywords1 = '||||||'\n",
    "keywords2 = '|'\n",
    "\n",
    "df[(df['message'].str.contains(keywords1)) & (df['message'].str.contains(keywords2))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
